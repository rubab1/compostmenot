{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, io\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf,vectorizer= pickle.load(open('CompostClassifier.pkl','rb'))\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma(word,lemmatizer=WordNetLemmatizer()):\n",
    "    _word = word.split(' ')\n",
    "    for i,_w in enumerate(_word):\n",
    "        _word[i] = lemmatizer.lemmatize(_w.lower())\n",
    "    return ' '.join(_word)\n",
    "\n",
    "def get_vect(x,vectorizer):\n",
    "    return vectorizer.transform(x).toarray()\n",
    "\n",
    "def get_class_weights(word,clf=clf,vectorizer=vectorizer):\n",
    "    return clf.predict_proba(get_vect(np.array([get_lemma(word)]),vectorizer))\n",
    "\n",
    "def get_weighted_class(vision,clf=clf,vectorizer=vectorizer):\n",
    "    i,x = 0,[]\n",
    "    for key,value in vision.items():\n",
    "        if i==0:\n",
    "            if clf.predict(get_vect(np.array([get_lemma(key)]),vectorizer))==0:\n",
    "                return 0\n",
    "            else:\n",
    "                i=1\n",
    "        x.append(value*get_class_weights(key,clf,vectorizer).T)\n",
    "    x = np.array(x).sum(axis=0)\n",
    "    return np.argmax(x/x.sum())\n",
    "\n",
    "\n",
    "def get_labels(filename,client=client):\n",
    "    with io.open(filename, 'rb') as image_file:\n",
    "        content=image_file.read()\n",
    "    image = types.Image(content=content)\n",
    "    response = client.label_detection(image=image)\n",
    "    labels,scores = [],[]\n",
    "    for label in response.label_annotations:\n",
    "        labels.append(label.description)\n",
    "        scores.append(label.score)\n",
    "    return dict(zip(labels,scores))\n",
    "\n",
    "def best_guess(vision,clf=clf,vectorizer=vectorizer):\n",
    "    pred = get_weighted_class(vision)\n",
    "    if pred==0:\n",
    "        col = 'red'\n",
    "        rec = 'CompostMeNot :-('\n",
    "        msg = 'Remember: anything labeled “Compostable” or “#7 PLA” goes to the food and yard waste.'\n",
    "    else:\n",
    "        col = 'green'\n",
    "        rec = 'CompostMe!!! Yaaaay!!!!!!'\n",
    "        msg = 'Remember: dry paper/cardboard products go to recycle, wet/greasy/soiled ones to compost.'\n",
    "    return col,rec,msg\n",
    "\n",
    "def DoAll(filename):\n",
    "    vision = get_labels(filename)\n",
    "    col,rec,msg = best_guess(vision)\n",
    "    rec = '\\n{:s}\\n'.format(rec)\n",
    "    return col,rec,msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "col,rec,msg = DoAll('optimization_images/024_leftover_dinner.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'green'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CompostMe!!! Yaaaay!!!!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'optimization_images/001_Chicken-Bones.jpg'\n",
    "vision = get_labels(filename)\n",
    "x = []\n",
    "tmp = []\n",
    "for key,value in vision.items():\n",
    "    tmp.append(get_class_weights(key,clf,vectorizer).T)\n",
    "    x.append(value*get_class_weights(key,clf,vectorizer).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Food': 0.9541228413581848, 'Dish': 0.9422977566719055, 'Cuisine': 0.9349826574325562, 'Meat': 0.8480419516563416, 'Ingredient': 0.8450334072113037, 'Pulled pork': 0.842769205570221, 'Kalua': 0.7459040284156799, 'Carnitas': 0.6611395478248596, 'Recipe': 0.600089430809021, 'Produce': 0.592475175857544}\n"
     ]
    }
   ],
   "source": [
    "print(vision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.02615632],\n",
      "       [0.97384368]]), array([[0.45048515],\n",
      "       [0.54951485]]), array([[0.32996346],\n",
      "       [0.67003654]]), array([[0.30526593],\n",
      "       [0.69473407]]), array([[0.32996346],\n",
      "       [0.67003654]]), array([[0.31015381],\n",
      "       [0.68984619]]), array([[0.32996346],\n",
      "       [0.67003654]]), array([[0.31687744],\n",
      "       [0.68312256]]), array([[0.32996346],\n",
      "       [0.67003654]]), array([[0.39121165],\n",
      "       [0.60878835]])]\n"
     ]
    }
   ],
   "source": [
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.02495635],\n",
      "       [0.92916649]]), array([[0.42449115],\n",
      "       [0.51780661]]), array([[0.30851011],\n",
      "       [0.62647255]]), array([[0.25887831],\n",
      "       [0.58916364]]), array([[0.27883014],\n",
      "       [0.56620326]]), array([[0.26138808],\n",
      "       [0.58138113]]), array([[0.24612107],\n",
      "       [0.49978296]]), array([[0.20950021],\n",
      "       [0.45163934]]), array([[0.19800758],\n",
      "       [0.40208185]]), array([[0.23178319],\n",
      "       [0.36069199]])]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30657843]\n",
      " [0.69342157]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array(x).sum(axis=0)\n",
    "print(x/x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
